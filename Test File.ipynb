{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6ce787198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6ce19b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6d0931208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Train Performance  Validation Performance\n",
      "No text feature                      1.084683                1.020327\n",
      "60 MCW                               1.060429                0.983940\n",
      "160 MCW                              1.047776                0.995069\n",
      "60 MCW with extra features           1.045277                0.974438\n",
      "All features                         1.032782                0.985008\n",
      "                  Closed Form  Gradient Descent\n",
      "Runtime low dim      0.000500          0.114233\n",
      "MSE low dim          1.084683          1.086848\n",
      "Runtime high dim     0.020444          0.363775\n",
      "MSE high dim         1.047776          1.047975\n",
      "1.2825331224983374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_exploration import feature_exploration\n",
    "from feature_exploration_plot import feature_exploration_plot\n",
    "from preprocess import preprocess\n",
    "from feature_extraction import feature_extraction\n",
    "from MSE import MSE\n",
    "from GD import gradient_descent\n",
    "from Linear_regression import Linear_regression\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "# Load data in json format and store in a dataframe\n",
    "with open(\"proj1_data.json\") as fp:\n",
    "    data = json.load(fp)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Convert true-false to 1-0\n",
    "df[\"is_root\"] = df[\"is_root\"].astype(int)\n",
    "\n",
    "# Convert all text to lower cases\n",
    "df[\"text\"]= [x.lower() for x in df[\"text\"]]\n",
    "\n",
    "# Parse text where there's a space\n",
    "df[\"text\"]= [x.split() for x in df[\"text\"]]\n",
    "\n",
    "# First 10000 data points as training set\n",
    "train = df.iloc[0:10000,:]\n",
    "\n",
    "# 10000 to 11000 as validation set\n",
    "validation = df.iloc[10000:11000,:]\n",
    "validation.index -= 10000\n",
    "\n",
    "# Last 1000 as test set\n",
    "test = df.iloc[11000:12000,:]\n",
    "test.index -= 11000\n",
    "\n",
    "# Explores the effect of proposed features on the targets\n",
    "data_feature_explore = feature_exploration(train)\n",
    "feature_exploration_plot(data_feature_explore)\n",
    "\n",
    "# Preprocess the data\n",
    "train, m_c_words = preprocess(train,160)\n",
    "train = train.values.astype(float)\n",
    "validation = feature_extraction(validation, m_c_words).values.astype(float)\n",
    "test = feature_extraction(test, m_c_words).values.astype(float)\n",
    "\n",
    "\n",
    "# Train Model\n",
    "\n",
    "# Trains the Linear model on different set of features and compares their performance on the validation set\n",
    "X_0 = train[:,0:4] # item start from 0 and end at (4-1)\n",
    "X_60 = train[:,0:64]\n",
    "X_160 = train[:,0:164]\n",
    "extra_features = train[:,164:-1]\n",
    "X_60_extra = np.concatenate((X_60, extra_features), axis=1)\n",
    "X_all = train[:,0:-1]\n",
    "y = train[:,-1]\n",
    "\n",
    "# Trains a Linear model on each training set\n",
    "w_optim_0, MSE_0 = Linear_regression(X_0, y,method = 0)\n",
    "w_optim_60, MSE_60 = Linear_regression(X_60, y,method = 0)\n",
    "w_optim_160, MSE_160 = Linear_regression(X_160, y,method = 0)\n",
    "w_optim_60_extra, MSE_60_extra = Linear_regression(X_60_extra, y,method = 0)\n",
    "w_optim, MSE_all = Linear_regression(X_all, y,method = 0)\n",
    "\n",
    "# Select validations set corresponding to the different training set chosen above\n",
    "val_0 = validation[:,0:4]\n",
    "val_60 = validation[:,0:64]\n",
    "val_160 = validation[:,0:164]\n",
    "val_extra_features = validation[:,164:-1]\n",
    "val_60_extra = np.concatenate((val_60, val_extra_features), axis=1)\n",
    "val_all = validation[:,0:-1]\n",
    "val_y = validation[:,-1]\n",
    "\n",
    "# Mean squared error on validation sets\n",
    "MSE_0_val = MSE(val_0, val_y, w_optim_0)\n",
    "MSE_60_val = MSE(val_60, val_y, w_optim_60)\n",
    "MSE_160_val = MSE(val_160, val_y, w_optim_160)\n",
    "MSE_all_val = MSE(val_all, val_y, w_optim)\n",
    "MSE_60_extra_val = MSE(val_60_extra, val_y, w_optim_60_extra)\n",
    "\n",
    "# MSE comparison table\n",
    "MSEs = [[MSE_0, MSE_0_val],[MSE_60, MSE_60_val],[MSE_160, MSE_160_val], [MSE_60_extra, MSE_60_extra_val], [MSE_all, MSE_all_val]]\n",
    "MSE_table = pd.DataFrame(data=MSEs, columns = ['Train Performance','Validation Performance'],\n",
    "                     index = ['No text feature','60 MCW', '160 MCW','60 MCW with extra features',\n",
    "                              'All features'])\n",
    "\n",
    "# Compares the runtime/stebility/performance of closed form vs gradient descent in high and low dimensional settings\n",
    "\n",
    "# Closed Form low dimension\n",
    "start_cf_ld = time.time()\n",
    "MSE_cf_ld = Linear_regression(X_0, y, method=0)[1]\n",
    "end_cf_ld = time.time()\n",
    "time_cf_ld = end_cf_ld - start_cf_ld\n",
    "\n",
    "# GD low dimension\n",
    "start_gd_ld = time.time()\n",
    "MSE_gd_ld = Linear_regression(X_0, y, None, alpha_0 = 1e-06, b = 0, eps = 1e-04)[1]\n",
    "end_gd_ld = time.time()\n",
    "time_gd_ld = end_gd_ld - start_gd_ld\n",
    "\n",
    "# Closed Form high dimension\n",
    "start_cf_hd = time.time()\n",
    "MSE_cf_hd = Linear_regression(X_160, y, method=0)[1]\n",
    "end_cf_hd = time.time()\n",
    "time_cf_hd = end_cf_hd - start_cf_hd\n",
    "\n",
    "# GD high dimension\n",
    "start_gd_hd = time.time()\n",
    "MSE_gd_hd = Linear_regression(X_160, y, None, alpha_0 = 5e-06, b = 0, eps = 1e-04)[1]\n",
    "end_gd_hd = time.time()\n",
    "time_gd_hd = end_gd_hd - start_gd_hd\n",
    "\n",
    "# Runtime comparison table\n",
    "runtime_table = pd.DataFrame(\n",
    "    [[time_cf_ld, time_gd_ld], [MSE_cf_ld, MSE_gd_ld], [time_cf_hd, time_gd_hd], [MSE_cf_hd, MSE_gd_hd]],\n",
    "     columns = ['Closed Form', 'Gradient Descent'], index=['Runtime low dim','MSE low dim', 'Runtime high dim', 'MSE high dim'])\n",
    "\n",
    "# Compare different learning rate/beta for GD / plot\n",
    "step_sizes = [1e-05, 5e-06, 1e-06, 5e-07, 1e-07]\n",
    "initial_weights = np.random.uniform(-5, 5, (5, 4))\n",
    "\n",
    "results_step_sizes = np.zeros((len(step_sizes)), dtype = np.ndarray)\n",
    "results_initial_weights = np.zeros((initial_weights.shape[0]), dtype = np.ndarray)\n",
    "\n",
    "for i in range(len(step_sizes)):\n",
    "    results_step_sizes[i] = np.array(Linear_regression(X_0, y, method = 1, w_0 = None, alpha_0 = step_sizes[i], b = 0, eps = 1e-06)[2])\n",
    "\n",
    "for i in range(initial_weights.shape[0]):\n",
    "    results_initial_weights[i] = np.array(Linear_regression(X_0, y, method = 1, w_0 = initial_weights[i,:], alpha_0 = 1e-06, b = 0, eps = 1e-06)[2])\n",
    "\n",
    "# Plots the different learning curves\n",
    "colors = [\"red\", \"blue\", \"green\", \"orange\", \"black\"]\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(step_sizes)):\n",
    "    plt.plot(np.linspace(0, 10 * len(results_step_sizes[i]), len(results_step_sizes[i])),\n",
    "             results_step_sizes[i], color = colors[i], label = 'alpha =' + str(step_sizes[i]))\n",
    "plt.xlabel(\"number of iterations\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0,200)\n",
    "plt.savefig('step_sizes.pdf')\n",
    "\n",
    "plt.figure()\n",
    "for i in range(initial_weights.shape[0]):\n",
    "    plt.plot(np.linspace(0, 10 * len(results_initial_weights[i]), len(results_initial_weights[i])), results_initial_weights[i], color = \"b\")\n",
    "plt.xlabel(\"number of iterations\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlim(0,200)\n",
    "plt.savefig('initial_weights.pdf')\n",
    "\n",
    "# Run best model on test set\n",
    "testset = np.concatenate((test[:,0:64],test[:,164:-1]),axis=1)\n",
    "test_y = test[:,-1]\n",
    "MSE_test = MSE(testset, test_y, w_optim_60_extra)\n",
    "\n",
    "# returns the results\n",
    "plt.show()\n",
    "print(MSE_table)\n",
    "print(runtime_table)\n",
    "print(MSE_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
