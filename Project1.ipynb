{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import operator\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "\n",
    "#Load data in json format and store in a dataframe\n",
    "with open(\"proj1_data.json\") as fp:\n",
    "    data = json.load(fp)\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert true-false to 1-0\n",
    "df[\"is_root\"] = df[\"is_root\"].astype(int)\n",
    "#Convert all text to lower cases\n",
    "df[\"text\"]= [x.lower() for x in df[\"text\"]]\n",
    "#Parse text where there's a space\n",
    "df[\"text\"]= [x.split() for x in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>is_root</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.254698</td>\n",
       "      <td>[its, raining, sideways]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>[wheel, of, time, reader, confirmed!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370827</td>\n",
       "      <td>[the, jungle, book, of, pussy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272843</td>\n",
       "      <td>[i'm, just, making, this, thread, since, there...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  controversiality  is_root  popularity_score  \\\n",
       "0         0                 0        0          1.254698   \n",
       "1         0                 0        0          0.509813   \n",
       "2         0                 0        1          0.370827   \n",
       "3         0                 0        0         -0.272843   \n",
       "\n",
       "                                                text  \n",
       "0                           [its, raining, sideways]  \n",
       "1              [wheel, of, time, reader, confirmed!]  \n",
       "2                     [the, jungle, book, of, pussy]  \n",
       "3  [i'm, just, making, this, thread, since, there...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 10000 data points as training set\n",
    "train = df.iloc[0:10000,:]\n",
    "#10000 to 11000 as validation set\n",
    "validation = df.iloc[10000:11000,:]\n",
    "validation.index -= 10000\n",
    "#Last 1000 as test set\n",
    "test = df.iloc[11000:12000,:]\n",
    "test.index -= 11000\n",
    "#Display the first 10 points of the training data\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def preprocess(dataset, nb_words):\n",
    "    \n",
    "    # Feature: Does the comment contain a question mark\n",
    "    qmarks = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Normalized comment length (number of words)\n",
    "    n_words = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Avg number of letters per words\n",
    "    letters_per_word = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Number of punctuation signs per word (, . ! ? : ;)\n",
    "    punctuation_count = np.zeros((dataset.shape[0]))\n",
    "    punct = [',', '.', '!', '?', ':', ';']\n",
    "    # Feature: Most common word count\n",
    "    l = np.concatenate(dataset[\"text\"])\n",
    "    most_common_words = [word for word, word_count in Counter(l).most_common(nb_words)]\n",
    "    zeros = np.zeros(shape = (dataset.shape[0], nb_words))\n",
    "    word_count_features = pd.DataFrame(zeros, columns = most_common_words)    \n",
    "    # Feature: Misspelled words\n",
    "    misspelled_feature = np.zeros(dataset.shape[0])\n",
    "    spell = SpellChecker()\n",
    "    #Feature: Swear words\n",
    "    swear_words = pd.read_csv(\"swearWords.csv\")\n",
    "    s_words = np.zeros(dataset.shape[0])\n",
    "    \n",
    "    \n",
    "    # Iterate over comments\n",
    "    for i in range(dataset.shape[0]):\n",
    "        txt = dataset.iloc[i][\"text\"]\n",
    "        # Iterate over words\n",
    "        for w in txt:\n",
    "            # most common words\n",
    "            for target in most_common_words:\n",
    "                if w == target:\n",
    "                    word_count_features.iloc[i][target] += 1\n",
    "            \n",
    "            #swear words count\n",
    "            for target in swear_words:\n",
    "                if w == target:\n",
    "                    s_words[i]+=1\n",
    "            \n",
    "            # punctuation count\n",
    "            for x in punct:\n",
    "                punctuation_count[i] += w.count(x)\n",
    "                \n",
    "            # question counter\n",
    "            if \"?\" in w:\n",
    "                qmarks[i] = 1\n",
    "                \n",
    "            # comment length\n",
    "            n_words[i] += 1\n",
    "            # number of letters\n",
    "            letters_per_word[i] += len(w)\n",
    "            \n",
    "    # misspelled count   \n",
    "    for i in range(dataset.shape[0]):\n",
    "        new = [re.sub(r\"^\\W+|\\W+$\",\"\", word) for word in dataset.iloc[i][\"text\"]]\n",
    "        misspelled_words = spell.unknown(new)\n",
    "        misspelled_feature[i] = len(misspelled_words)\n",
    "    \n",
    "    # Get average number of letters per word\n",
    "    for i in range(dataset.shape[0]):\n",
    "        letters_per_word[i] = letters_per_word[i]/n_words[i]\n",
    "        \n",
    "    # Get average punctuation marks per word\n",
    "    for i in range(dataset.shape[0]):\n",
    "        punctuation_count[i] = punctuation_count[i]/n_words[i]\n",
    "        \n",
    "    # Add feature columns \n",
    "    # Most common words\n",
    "    dataset = pd.concat([dataset, word_count_features], axis=1)\n",
    "    # Misspelled words count\n",
    "    dataset = dataset.assign(misspelled=pd.Series(misspelled_feature).values)\n",
    "    # Swear words\n",
    "    dataset = dataset.assign(s_words=pd.Series(s_words).values)\n",
    "    # Question marks\n",
    "    dataset = dataset.assign(has_question=pd.Series(qmarks).values.astype(int))\n",
    "    # Avg letters per word\n",
    "    dataset = dataset.assign(letters_per_word=pd.Series(letters_per_word).values)\n",
    "    # Punctuation per word\n",
    "    dataset = dataset.assign(punctuation_count=pd.Series(punctuation_count).values)\n",
    "    #Add bias term\n",
    "    ones = np.ones((dataset.shape[0]))\n",
    "    dataset = dataset.assign(bias = pd.Series(ones).values)\n",
    "     #Drop text column\n",
    "    dataset = dataset.drop([\"text\"], axis=1)\n",
    "    #Move y value to the end\n",
    "    dataset = dataset[[\"bias\"] + [c for c in dataset if c not in [\"popularity_score\",\"bias\"]] + [\"popularity_score\"]]\n",
    "    return (dataset, most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelled</th>\n",
       "      <th>s_words</th>\n",
       "      <th>has_question</th>\n",
       "      <th>letters_per_word</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>popularity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.254698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.509813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-0.272843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.560150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.710526</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.696554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.050417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.310543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.478261</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-1.208735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.075000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.123700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.984134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>2.410364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.476190</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.173580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.070175</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.435761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.014885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.357482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.252674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.327476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.035714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.044132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.358714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.186441</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>1.231302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.065862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.203316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.458871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.932721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-1.462292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.518780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.864407</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>-4.054541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.351351</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>1.334129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.037037</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.490316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.445595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.402741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.712636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.571823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.181084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.579202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.022727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>5.031895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.395680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.315789</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.431806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.533816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.837500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.657295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.654206</td>\n",
       "      <td>0.093458</td>\n",
       "      <td>0.110152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.738615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.724105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.826087</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.454526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.652174</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.450136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.487767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.608980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.514308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.265267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.158110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.893071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.140330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      misspelled  s_words  has_question  letters_per_word  punctuation_count  \\\n",
       "0            0.0      0.0             0          6.000000           0.000000   \n",
       "1            0.0      0.0             0          5.400000           0.200000   \n",
       "2            0.0      1.0             0          4.000000           0.000000   \n",
       "3            1.0      0.0             0          4.000000           0.071429   \n",
       "4            4.0      0.0             1          6.250000           0.230769   \n",
       "5            1.0      1.0             0          3.710526           0.078947   \n",
       "6            0.0      0.0             0          4.000000           0.166667   \n",
       "7            1.0      0.0             0          4.615385           0.076923   \n",
       "8            1.0      0.0             0          4.478261           0.086957   \n",
       "9            3.0      0.0             0          4.075000           0.100000   \n",
       "10           1.0      0.0             0          3.760000           0.040000   \n",
       "11           2.0      0.0             0          4.545455           0.075758   \n",
       "12           1.0      0.0             0          4.571429           0.142857   \n",
       "13           1.0      0.0             0          4.476190           0.095238   \n",
       "14           2.0      0.0             1          3.777778           0.111111   \n",
       "15           1.0      0.0             0          4.070175           0.122807   \n",
       "16           1.0      0.0             0          4.347826           0.043478   \n",
       "17           2.0      0.0             0          4.818182           0.818182   \n",
       "18           1.0      0.0             0          3.500000           0.250000   \n",
       "19           2.0      0.0             0          4.266667           0.148148   \n",
       "20           0.0      0.0             0          4.035714           0.107143   \n",
       "21           1.0      0.0             0          6.750000           0.250000   \n",
       "22           2.0      0.0             0          4.186441           0.135593   \n",
       "23           2.0      0.0             0          5.100000           0.400000   \n",
       "24           0.0      0.0             0          3.600000           0.133333   \n",
       "25           0.0      0.0             0          9.000000           0.000000   \n",
       "26           0.0      1.0             0          5.333333           0.333333   \n",
       "27           1.0      0.0             0          4.937500           0.062500   \n",
       "28           1.0      0.0             1          4.400000           0.133333   \n",
       "29           2.0      0.0             0          4.615385           0.076923   \n",
       "...          ...      ...           ...               ...                ...   \n",
       "9970         4.0      3.0             0          3.864407           0.135593   \n",
       "9971         1.0      1.0             0          4.351351           0.135135   \n",
       "9972         2.0      0.0             0          5.037037           0.111111   \n",
       "9973         0.0      0.0             0          5.000000           0.000000   \n",
       "9974         0.0      0.0             0          4.000000           0.076923   \n",
       "9975         0.0      0.0             0          9.000000           0.000000   \n",
       "9976         0.0      0.0             0          4.750000           0.125000   \n",
       "9977         1.0      0.0             1         23.000000           3.000000   \n",
       "9978         1.0      0.0             0          4.818182           0.136364   \n",
       "9979         1.0      0.0             0          5.200000           0.200000   \n",
       "9980         3.0      0.0             0          4.750000           0.125000   \n",
       "9981         0.0      0.0             0          4.022727           0.090909   \n",
       "9982         0.0      0.0             0          3.571429           0.000000   \n",
       "9983         1.0      0.0             0          4.315789           0.105263   \n",
       "9984         1.0      0.0             0          5.600000           0.800000   \n",
       "9985         1.0      0.0             0          3.837500           0.037500   \n",
       "9986         6.0      0.0             0          4.654206           0.093458   \n",
       "9987         0.0      0.0             0          4.857143           0.142857   \n",
       "9988         1.0      0.0             0          2.000000           0.000000   \n",
       "9989         1.0      0.0             0          4.826087           0.130435   \n",
       "9990         0.0      0.0             0          3.500000           0.000000   \n",
       "9991         1.0      0.0             0          4.652174           0.086957   \n",
       "9992         0.0      0.0             0          2.888889           0.000000   \n",
       "9993         1.0      0.0             1          4.200000           0.200000   \n",
       "9994         1.0      0.0             0          3.520000           0.080000   \n",
       "9995         0.0      0.0             0          8.250000           0.000000   \n",
       "9996         0.0      0.0             0          5.000000           0.500000   \n",
       "9997         4.0      0.0             1          6.250000           0.230769   \n",
       "9998         4.0      0.0             1         13.142857           0.428571   \n",
       "9999         1.0      0.0             0          4.571429           0.428571   \n",
       "\n",
       "      popularity_score  \n",
       "0             1.254698  \n",
       "1             0.509813  \n",
       "2             0.370827  \n",
       "3            -0.272843  \n",
       "4             0.560150  \n",
       "5             0.696554  \n",
       "6             1.050417  \n",
       "7             0.310543  \n",
       "8            -1.208735  \n",
       "9             1.123700  \n",
       "10            1.984134  \n",
       "11            2.410364  \n",
       "12            0.307555  \n",
       "13            0.005166  \n",
       "14            0.173580  \n",
       "15            0.435761  \n",
       "16            0.014885  \n",
       "17            0.357482  \n",
       "18            0.252674  \n",
       "19            0.327476  \n",
       "20            0.044132  \n",
       "21            0.358714  \n",
       "22            1.231302  \n",
       "23            1.065862  \n",
       "24            0.203316  \n",
       "25            0.665754  \n",
       "26            3.458871  \n",
       "27            1.932721  \n",
       "28           -1.462292  \n",
       "29            0.518780  \n",
       "...                ...  \n",
       "9970         -4.054541  \n",
       "9971          1.334129  \n",
       "9972          0.490316  \n",
       "9973          1.445595  \n",
       "9974          0.402741  \n",
       "9975          0.692070  \n",
       "9976          0.521959  \n",
       "9977          0.712636  \n",
       "9978          0.571823  \n",
       "9979         -0.181084  \n",
       "9980          0.579202  \n",
       "9981          5.031895  \n",
       "9982          2.395680  \n",
       "9983          0.431806  \n",
       "9984          1.533816  \n",
       "9985          0.657295  \n",
       "9986          0.110152  \n",
       "9987          0.738615  \n",
       "9988         -0.724105  \n",
       "9989          0.454526  \n",
       "9990          0.883070  \n",
       "9991          0.450136  \n",
       "9992          0.898211  \n",
       "9993          0.487767  \n",
       "9994          0.608980  \n",
       "9995          4.514308  \n",
       "9996          0.265267  \n",
       "9997          0.158110  \n",
       "9998          0.893071  \n",
       "9999          0.140330  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].iloc[:,164:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(dataset, words):\n",
    "    \n",
    "    # Feature: Does the comment contain a question mark\n",
    "    qmarks = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Normalized comment length (number of words)\n",
    "    n_words = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Avg number of letters per words\n",
    "    letters_per_word = np.zeros((dataset.shape[0]))\n",
    "    # Feature: Number of punctuation signs per word (, . ! ? : ;)\n",
    "    punctuation_count = np.zeros((dataset.shape[0]))\n",
    "    punct = [',', '.', '!', '?', ':', ';']\n",
    "    # Feature: Most common word count\n",
    "    most_common_words = words\n",
    "    zeros = np.zeros(shape = (dataset.shape[0], len(words)))\n",
    "    word_count_features = pd.DataFrame(zeros, columns = most_common_words)    \n",
    "    # Feature: Misspelled words\n",
    "    misspelled_feature = np.zeros(dataset.shape[0])\n",
    "    spell = SpellChecker()\n",
    "    #Feature: Swear words\n",
    "    swear_words = pd.read_csv(\"swearWords.csv\")\n",
    "    s_words = np.zeros(dataset.shape[0])\n",
    "    \n",
    "    \n",
    "    # Iterate over comments\n",
    "    for i in range(dataset.shape[0]):\n",
    "        txt = dataset.iloc[i][\"text\"]\n",
    "        # Iterate over words\n",
    "        for w in txt:\n",
    "            # most common words\n",
    "            for target in most_common_words:\n",
    "                if w == target:\n",
    "                    word_count_features.iloc[i][target] += 1\n",
    "            \n",
    "            #swear words count\n",
    "            for target in swear_words:\n",
    "                if w == target:\n",
    "                    s_words[i]+=1\n",
    "            \n",
    "            # punctuation count\n",
    "            for x in punct:\n",
    "                punctuation_count[i] += w.count(x)\n",
    "                \n",
    "            # question counter\n",
    "            if \"?\" in w:\n",
    "                qmarks[i] = 1\n",
    "                \n",
    "            # comment length\n",
    "            n_words[i] += 1\n",
    "            # number of letters\n",
    "            letters_per_word[i] += len(w)\n",
    "            \n",
    "    # misspelled count   \n",
    "    for i in range(dataset.shape[0]):\n",
    "        new = [re.sub(r'[^a-zA-Z]', '', x) for x in dataset.iloc[i][\"text\"]]\n",
    "        misspelled_words = spell.unknown(new)\n",
    "        misspelled_feature[i] = len(misspelled_words)\n",
    "    \n",
    "    # Get average number of letters per word\n",
    "    for i in range(dataset.shape[0]):\n",
    "        letters_per_word[i] = letters_per_word[i]/n_words[i]\n",
    "        \n",
    "    # Get average punctuation marks per word\n",
    "    for i in range(dataset.shape[0]):\n",
    "        punctuation_count[i] = punctuation_count[i]/n_words[i]\n",
    "                    \n",
    "    # Add feature columns \n",
    "    # Most common words\n",
    "    dataset = pd.concat([dataset, word_count_features], axis=1)\n",
    "    # Misspelled words count\n",
    "    dataset = dataset.assign(misspelled=pd.Series(misspelled_feature).values)\n",
    "    # Swear words\n",
    "    dataset = dataset.assign(s_words=pd.Series(s_words).values)\n",
    "    # Question marks\n",
    "    dataset = dataset.assign(has_question=pd.Series(qmarks).values.astype(int))\n",
    "    # Avg letters per word\n",
    "    dataset = dataset.assign(letters_per_word=pd.Series(letters_per_word).values)\n",
    "    # Punctuation per word\n",
    "    dataset = dataset.assign(punctuation_count=pd.Series(punctuation_count).values)\n",
    "    #Add bias term\n",
    "    ones = np.ones((dataset.shape[0]))\n",
    "    dataset= dataset.assign(bias = pd.Series(ones).values)\n",
    "    #Drop text column\n",
    "    dataset = dataset.drop([\"text\"], axis=1)\n",
    "    #Move y value to the end\n",
    "    dataset = dataset[[\"bias\"] +[c for c in dataset if c not in [\"popularity_score\"]] + [\"popularity_score\"]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7cff5d3aa27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b57b01113c79>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(dataset, nb_words)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpunct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Feature: Most common word count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmost_common_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "train, words = preprocess(train,5)\n",
    "train = train.values.astype(float)\n",
    "validation = feature_extraction(validation, words).values.astype(float)\n",
    "test = feature_extraction(test, words).values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.         ...  0.2         1.\n",
      "   0.84333697]\n",
      " [ 1.          0.          0.         ...  0.5         1.\n",
      "   0.89400237]\n",
      " [ 1.          2.          0.         ...  0.1         1.\n",
      "   3.42605184]\n",
      " ...\n",
      " [ 1.          0.          0.         ...  0.          1.\n",
      "   0.65148906]\n",
      " [ 1.          0.          0.         ...  0.15384615  1.\n",
      "   1.01984666]\n",
      " [ 1.          4.          0.         ...  0.1875      1.\n",
      "  -0.74624472]]\n"
     ]
    }
   ],
   "source": [
    "def MSE(X, y, w):\n",
    "    return np.mean((X @ w - y)**2)\n",
    "X = validation[:,0:4]\n",
    "y = validation[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Jenny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "def sentiment(dataset, words):\n",
    "    l = reduce(operator.concat, dataset[\"text\"])\n",
    "    most_common_words = [word for word, word_count in Counter(l).most_common(words)]\n",
    "    stop = stopwords.words('english')\n",
    "    for i in range(dataset.shape[0]):\n",
    "        txt = dataset.iloc[i][\"text\"]\n",
    "        for w in txt:\n",
    "            if w in stop:\n",
    "                txt.remove(w)\n",
    "    #remove most common words\n",
    "            if w in most_common_words:\n",
    "                txt.remove(w)\n",
    "    #Correct misspelled\n",
    "           # w.correct()\n",
    "    #Lemmatization\n",
    "            #w.lemmatize()\n",
    "    #Sentiment analysis\n",
    "        polarity, subjectivity = txt.sentiment()\n",
    "        \n",
    "    train['sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GD import gradient_descent\n",
    "import time\n",
    "def Linear_regression(X, y, method = 0, w_0 = None, alpha_0 = 1, b = 1, eps = 1e-06):\n",
    "\n",
    "    # local variables\n",
    "    p = X.shape[1]\n",
    "    optim_w = np.zeros(p)\n",
    "\n",
    "    # computes the optimal weights using the closed form solution\n",
    "    if(method == 0):\n",
    "        X_T = X.T\n",
    "        b = X_T @ y\n",
    "        A = X_T @ X\n",
    "        \n",
    "        optim_w = np.linalg.solve(A,b)\n",
    "\n",
    "        return optim_w\n",
    "\n",
    "    # computes the optimal weights using gradient descent\n",
    "    else:\n",
    "        if w_0 is None:\n",
    "            w_0 = np.zeros(p)\n",
    "\n",
    "        optim_w = gradient_descent(X, y, w_0, alpha_0, b, eps)\n",
    "\n",
    "        return optim_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_0, alpha_0, b, eps):\n",
    "\n",
    "    # local variables\n",
    "    i = 0 # iterations performed\n",
    "    alpha = alpha_0 # step size\n",
    "    prev_w = w_0 # weight of previous iteration\n",
    "    current_w = w_0 # weight of current iteration\n",
    "\n",
    "    # precomputes terms used in the gradient descent update\n",
    "    X_T = X.T\n",
    "    crossprod_X = X_T @ X\n",
    "    y_term = X_T @ y\n",
    "\n",
    "    # performs gradient descent until stopping condition reached\n",
    "    while True:\n",
    "\n",
    "        # updates the step size\n",
    "        alpha = alpha_0/(1 + b*i)\n",
    "\n",
    "        # updates the weights\n",
    "        prev_w = current_w\n",
    "        current_w = current_w - 2 * alpha * (crossprod_X @ current_w - y_term)\n",
    "\n",
    "        # updates the iteration number\n",
    "        i = i + 1\n",
    "\n",
    "        # checks the stopping condition\n",
    "        if np.linalg.norm(current_w - prev_w) < eps:\n",
    "            break\n",
    "\n",
    "    # returns the optimal weights\n",
    "    return current_w\n",
    "\n",
    "from sympy.solvers import solve\n",
    "def Linear_regression(X, y, method = 0, w_0 = None, alpha_0 = 1, b = 1, eps = 1e-06):\n",
    "\n",
    "    # local variables\n",
    "    p = X.shape[1]\n",
    "    optim_w = np.zeros(p)\n",
    "\n",
    "    # computes the optimal weights using the closed form solution\n",
    "    if(method == 0):\n",
    "        X_T = X.T\n",
    "        b = X_T @ y\n",
    "        A = X_T @ X\n",
    "        \n",
    "        optim_w = np.linalg.inv(A)@b \n",
    "        #optim_w = np.linalg.solve(A,b)\n",
    "\n",
    "\n",
    "\n",
    "        return optim_w\n",
    "\n",
    "    # computes the optimal weights using gradient descent\n",
    "    else:\n",
    "        if w_0 is None:\n",
    "            w_0 = np.zeros(p)\n",
    "\n",
    "        optim_w = gradient_descent(X, y, w_0, alpha_0, b, eps)\n",
    "\n",
    "        return optim_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.45983041e-01  3.75533780e-01 -1.09554785e+00 -2.33466789e-01\n",
      " -3.34379529e-03 -4.06777600e-04 -7.57469048e-03  8.38157340e-03\n",
      "  2.98382428e-02 -3.79098679e-03  6.19035359e-02 -1.00117708e-01\n",
      " -5.17723460e-03  2.13392348e-02] 0.00510096549987793\n"
     ]
    }
   ],
   "source": [
    "X = train[:,:-1]\n",
    "y = train[:,-1]\n",
    "\n",
    "start_cf = time.time()\n",
    "linreg = Linear_regression(X, y, method = 0)\n",
    "end_cf = time.time()\n",
    "\n",
    "time_cf = end_cf - start_cf\n",
    "\n",
    "print(linreg, time_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.45983040e-01  3.75533780e-01 -1.09554781e+00 -2.33466789e-01\n",
      " -3.34379529e-03 -4.06777542e-04 -7.57469053e-03  8.38157348e-03\n",
      "  2.98382427e-02 -3.79098682e-03  6.19035355e-02 -1.00117708e-01\n",
      " -5.17723461e-03  2.13392350e-02] 1.6073899269104004\n"
     ]
    }
   ],
   "source": [
    "start_gd = time.time()\n",
    "gd = Linear_regression(X, y, method = 1, alpha_0 = 1e-06, b = 0, eps = 1e-11)\n",
    "end_gd = time.time()\n",
    "time_gd = end_gd - start_gd\n",
    "print(gd, time_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
